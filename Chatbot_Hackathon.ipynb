{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yamini8490/python8490/blob/main/Chatbot_Hackathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCfzqHTCh9la"
      },
      "source": [
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWC6jnVaPn-a"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUMw8NlY9UAc"
      },
      "source": [
        "Build a conversational bot to interact with the user using 2 approaches (Alexa Chatbot and Python Chatbot) for the given skill and achieve desired outcomes through the conversation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiQpi0NQjb6T"
      },
      "source": [
        "### It is recommended to watch the chatbot code explanation video before start working on the Hackathon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "0IfX7sjUjheb",
        "outputId": "aa53bba7-e41a-4093-b124-b9af06392d6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video width=\"854\" height=\"480\" controls>\n",
              "  <source src=\"https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/Walkthrough/b17_hackathon_1_chatbot_walkthrough.mp4\" type=\"video/mp4\">\n",
              "</video>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#@title Chatbot Code Explanation Video\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<video width=\"854\" height=\"480\" controls>\n",
        "  <source src=\"https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/Walkthrough/b17_hackathon_1_chatbot_walkthrough.mp4\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLPcxDRgI53J"
      },
      "source": [
        "## Skill to be developed as per the intents allocation\n",
        "\n",
        "**Zodiac Sign:** The bot should give the Zodiac Sign of the user, based on the date of birth (day, month and year) provided by the user **(This intent is common for everyone)**\n",
        "\n",
        "**Suggest a Movie:** The bot should suggest a movie based on user preferences: Language, Actor, Genre and other details\n",
        "\n",
        "**Find the Restaurant:**  Find the restaurants based on Cuisine, Cost type (cheap, medium, expensive), location and other parameters\n",
        "\n",
        "**Suggest a Book:** The bot should suggest the book based on user preferences: Author, language, genre and other parameters\n",
        "\n",
        "**Recommend a Store:** The bot should search a store based on preferences: Store type (medical clinics, food store, dry cleaning and more), location, availability (Open, Close) and other parameters\n",
        "\n",
        "Teams will be creating a conversational chatbot for the intents allocated to them\n",
        "\n",
        "> Team A =\tGroup\t\t1, 5, 9, 13, 17, 21  => Suggest a Movie & Zodiac Sign\n",
        "\n",
        "> Team B =  Group   2, 6, 10, 14, 18, 22 => Find a Restaurant & Zodiac Sign\n",
        "\n",
        "> Team C =  Group   3, 7, 11, 15, 19, 23  => Suggest a Book & Zodiac Sign\n",
        "\n",
        "> Team D =  Group   4, 8, 12, 16, 20, 24 =>  Recommend a Store & Zodiac Sign"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cbdKF1E-0lt"
      },
      "source": [
        "* For Zodiac sign Intent, all the required utterances, slots and params (JSON) files are provided for your reference. A csv file is also provided to perform the action\n",
        "\n",
        "\n",
        "* For the another allocated intent, create all the required files (utterances, slots and params) and perform the action by creating a csv file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNQWDhx7GGNh"
      },
      "source": [
        "# Alexa Chatbot (Total Marks = 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ43g3WCTAQv"
      },
      "source": [
        "**Note:**\n",
        "- Complete all of the tasks mentioned below from the [link](https://developer.amazon.com/alexa/console/ask) to work on the Alexa chatbot.\n",
        "- Go through the Pre-Hackathon for Alexa ChatBot material to understand Alexa Chatbot’s code and it's architecture.\n",
        "\n",
        "### **Criteria for evaluation**\n",
        "\n",
        "**Task1 (2Marks)** - Create a skill and provide intents based on team allocation\n",
        "- **Note:** You should create multiple intents under one skill, so that you can use that skill for testing\n",
        "\n",
        "**Task2 (4Marks)** - Create at least 50 utterances for each intent\n",
        "\n",
        "**Task3 (2Marks)** - Create at least 3 slots with the slot types for each intent\n",
        "- Hint: [Slot type references](https://developer.amazon.com/en-US/docs/alexa/custom-skills/slot-type-reference.html#list-slot-types)\n",
        "\n",
        "**Task4 (4Marks)** - Create a database with all possible combinations of all attributes (can be a CSV ﬁle) along with possible outcome for each combination. This database will be used for performing an action. Minimum 10 combinations\n",
        "  - Create a CSV file for the allocated intent other than Zodiac sign\n",
        "\n",
        "**Task5 (4Marks)** - Update the lambda_function.py and requirements.txt in the Code section - Refer PRE-HACKATHON Alexa ChatBot material\n",
        "\n",
        "\n",
        "**Task6 (4Marks)** - Run and test the Alexa chatbot for both the intents with the following:\n",
        "  - Alexa Chatbot should identify the user requirement.\n",
        "  - Gather the data from user input and get the relevant output.\n",
        "  - It should prompt the user with different prompts if the required input is not fulfilled.\n",
        "  - It should shift between the intents and maintain the dialogue flow.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ5D6hR6hiTZ"
      },
      "source": [
        "# Python Chatbot (Total Marks = 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPBwZyi1hwuF"
      },
      "source": [
        "**Note:** Complete all of the tasks mentioned below in this colab notebook to work on the Python chatbot.\n",
        "\n",
        "### **Criteria for evaluation**\n",
        "\n",
        "**Task1 (6Marks)** - Create .dat files for your intent (as the .dat files of Zodiac intent is already provided) based on the team allocation. Also, configure file in the params folder (Refer the given zodiac sign file for more information).\n",
        "\n",
        "   * Give minimum 50 utterances for each intent. Give the details in the **intent folder** -> *intent_name.dat* file. (Hint: You can use the same utterances which was created for Alexa chatbot)\n",
        "\n",
        "   * Give minimum 3 slots for each intent. Create a different *.dat* file for each slot under the **Slots folder** (Hint: You can use the same slots which was created for Alexa chatbot)\n",
        "\n",
        "   * Conﬁgure *params.cfg* ﬁle for the skill given to you under the **params folder**. Setup the intents in the same file with its required elements like Parameters, actions, etc. Refer to Zodiac Sign files for more information.\n",
        "\n",
        "**Task2 (2Marks)** - Create a database for the intent with all possible combinations of all attributes (can be a CSV ﬁle) along with possible outcome for each combination. Minimum 10 combinations. (Hint: You can use the same database which was created for Alexa chatbot)\n",
        "\n",
        "  * Create a CSV file for the allocated intent other than Zodiac sign\n",
        "\n",
        "**Task3 (5Marks)** - Text Representation and Classifications for both the intents\n",
        "\n",
        "* Create a numerical representation of the text data (utterances) by using **any one** of the following process:\n",
        "\n",
        "  - [Countvectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n",
        "\n",
        "    OR\n",
        "\n",
        "  - [TFIDFVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
        "\n",
        "* Perform a classification using the extracted features and classify the intent.\n",
        "\n",
        "**Task4 (4Marks)** - Compare the attributes with the CSV file and get the final selection of that particular intent.\n",
        "\n",
        "* Action function for the zodiac sign is already given. Similarly create action function for your intent and give the function name as mentioned in the params.cfg file.\n",
        "\n",
        "**Task5 (3Marks)** - Run and test the Python chatbot for both the intents with the following:\n",
        "  - Python Chatbot should identify the user requirement.\n",
        "  - Gather the data from user input and get the relevant output.\n",
        "  - It should prompt the user with different prompts if the required input is not fulfilled.\n",
        "  - It should shift between the intents and maintain the dialogue flow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48cT_Ybr818p"
      },
      "source": [
        "### Below is the code for updating the Python Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3yu1dJGBnbe",
        "outputId": "b47b9321-2a29-455d-9545-a48be4f8c60a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data downloaded successfully\n"
          ]
        }
      ],
      "source": [
        "#@title Run this cell to download the data\n",
        "!wget -qq https://cdn.iiith.talentsprint.com/aiml/Hackathon_data/Chatbot_Hackathon.zip\n",
        "!unzip -qq Chatbot_Hackathon.zip\n",
        "print(\"Data downloaded successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpZ-i7ndxPzU",
        "outputId": "60a2eea2-7ed8-4653-a7c7-8264c587e6e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# Import Libraries\n",
        "import json\n",
        "import random\n",
        "import os\n",
        "import re\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "# Importing context and .py script files\n",
        "from Context import *\n",
        "from Intent import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lR6rVhnwDQVd"
      },
      "source": [
        "### Chatbot Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSwQI3v0H6kR"
      },
      "source": [
        "Defining functions for Loading Intent, Collecting params, Checking actions, Getting Attributes and Identifying Intents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v9CMK_7tdbac"
      },
      "outputs": [],
      "source": [
        "def loadIntent(path, intent):\n",
        "    with open(path) as fil:\n",
        "        dat = json.load(fil)\n",
        "        intent = dat[intent]\n",
        "        #print(dat,intent)\n",
        "        return Intent(intent['intentname'],intent['Parameters'], intent['actions'])\n",
        "\n",
        "def check_required_params(current_intent, attributes, context):\n",
        "    '''Collects attributes pertaining to the current intent'''\n",
        "    for para in current_intent.params:\n",
        "        if para.required:\n",
        "            if para.name not in attributes:\n",
        "                return random.choice(para.prompts), context\n",
        "    return None, context\n",
        "\n",
        "def check_actions(current_intent, attributes, context):\n",
        "    '''This function performs the action for the intent as mentioned\n",
        "    in the intent config file. Performs actions pertaining to current intent '''\n",
        "    context = IntentComplete()\n",
        "    if current_intent.action.endswith('()'):\n",
        "        return eval(current_intent.action), context\n",
        "    return current_intent.action, context\n",
        "\n",
        "def getattributes(uinput,context,attributes, intent):\n",
        "    '''This function marks the slots in user input, and updates\n",
        "    the attributes dictionary'''\n",
        "    uinput = \" \"+uinput.lower()+\" \"\n",
        "    if context.name.startswith('IntentComplete'):\n",
        "        return attributes, uinput\n",
        "    else:\n",
        "        files = os.listdir(path_slots)\n",
        "        slots = {}\n",
        "        for fil in files:\n",
        "            if fil == \".ipynb_checkpoints\":\n",
        "                continue\n",
        "            lines = open(path_slots+fil).readlines()\n",
        "            for i, line in enumerate(lines):\n",
        "                line = line.strip()\n",
        "                if len(uinput.split(\" \"+line.lower()+\" \")) > 1:\n",
        "                    slots[line] = fil[:-4]\n",
        "        for value, slot in slots.items():\n",
        "            if intent != None and slot in \" \".join([param.name for param in intent.params]):\n",
        "                uinput = re.sub(value,r'$'+slot,uinput,flags=re.IGNORECASE)\n",
        "                attributes[slot] = value\n",
        "            else:\n",
        "                uinput = re.sub(value,r'$'+slot,uinput,flags=re.IGNORECASE)\n",
        "                attributes[slot] = value\n",
        "        return attributes, uinput\n",
        "\n",
        "def input_processor(user_input, context, attributes, intent):\n",
        "    '''Update the attributes, abstract over the slots in user input'''\n",
        "    attributes, cleaned_input = getattributes(user_input, context, attributes, intent)\n",
        "    return attributes, cleaned_input\n",
        "\n",
        "def intentIdentifier(clean_input, context,current_intent):\n",
        "    clean_input = clean_input.lower()\n",
        "    if (current_intent==None):\n",
        "        return loadIntent(path_param,intentPredict(clean_input))\n",
        "    else:\n",
        "        #If current intent is not none, stick with the ongoing intent\n",
        "        #return current_intent\n",
        "        intent = loadIntent(path_param,intentPredict(clean_input))\n",
        "        #print(\"intent:\",intent)\n",
        "        if current_intent != intent:\n",
        "            #print(current_intent,intent)\n",
        "            for para in current_intent.params:\n",
        "                if para.name in clean_input:\n",
        "                    return current_intent\n",
        "        return loadIntent(path_param,intentPredict(clean_input))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9fHBxSLtsXJ"
      },
      "source": [
        "Session class is one active session of the chatbot which the user interacts with. Let's go into the details:\n",
        "\n",
        "**reply( )** is the important one in our session object it takes user_input as a parameter and calls different modules of the chatbot architecture:\n",
        "\n",
        "\n",
        "*   **input_processor( )** - It helps in preprocessing and fetching the slots that can identify in the ready state\n",
        "    \n",
        "    - **getattributes( )** - It helps in identifying all the slots in the user utterance. Identify and map them to the parameters\n",
        "    \n",
        "    \n",
        "*   **intentIdentifier( )**\n",
        "\n",
        "  -  **intentPredict()** - Task to complete\n",
        "\n",
        "*   **check_required_params( )** - Based on the current intents, it goes over it's parameters\n",
        "\n",
        "*   **check_actions( )** - This function performs the action for the intent\n",
        "\n",
        "**Note:** Refer the *Chatbot_Reading_Material.pdf* for more information on the conversation flow\n",
        "\n",
        "\n",
        "       \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "x5ZB31PKE1zd"
      },
      "outputs": [],
      "source": [
        "class Session:\n",
        "    def __init__(self, attributes=None, active_contexts=[FirstGreeting(), IntentComplete() ]):\n",
        "        '''Initialise a default session'''\n",
        "        # Active contexts not used yet, can use it to have multiple contexts\n",
        "        self.active_contexts = active_contexts\n",
        "\n",
        "        # Contexts are flags which control dialogue flow\n",
        "        self.context = FirstGreeting()\n",
        "\n",
        "        # Intent tracks the current state of dialogue\n",
        "        self.current_intent = None\n",
        "\n",
        "        # attributes hold the information collected over the conversation\n",
        "        self.attributes = {}\n",
        "\n",
        "    def reply(self, user_input):\n",
        "        '''Generate response to user input'''\n",
        "        self.attributes, clean_input = input_processor(user_input, self.context, self.attributes, self.current_intent)\n",
        "\n",
        "        self.current_intent = intentIdentifier(clean_input, self.context, self.current_intent)\n",
        "\n",
        "        prompt, self.context = check_required_params(self.current_intent, self.attributes, self.context)\n",
        "\n",
        "        # prompt being None means all parameters satisfied, perform the intent action\n",
        "        if prompt is None and self.context.name!='IntentComplete':\n",
        "            prompt, self.context = check_actions(self.current_intent, self.attributes, self.context)\n",
        "\n",
        "        return prompt, self.attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztNFwTl_clJD"
      },
      "source": [
        "### Task1 (6Marks)\n",
        "\n",
        "Create .dat files for your intent based on the team allocation. Also, configure file in the params folder (Refer the given zodiac sign file for more information).\n",
        "\n",
        "   * Give minimum 50 utterances for each intent. You can use the same utterances which were created for Alexa chatbot. Give the details in the **intent folder** -> *intent_name.dat* file\n",
        "\n",
        "   * Give minimum 3 slots for each intent. You can use the same slots which were created for Alexa chatbot. Create a different *.dat* file for each slot under the **Slots folder**\n",
        "\n",
        "   * Conﬁgure *params.cfg* ﬁle for the skill given to you under the **params folder**. Setup the intents in the same file with its required elements like Parameters, actions, etc. Refer to Zodiac Sign file for more information.\n",
        "\n",
        "Once dat files are created, you can upload them in colab as path details given in the below code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aM7DzOSxQTOh"
      },
      "outputs": [],
      "source": [
        "path_param = 'Chatbot/params/params.cfg'\n",
        "path_utterances = 'Chatbot/utterances/'\n",
        "path_slots = 'Chatbot/slots/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTLngIU1AWkO"
      },
      "source": [
        "### Task2 (2Marks)\n",
        "\n",
        "Create a database with all possible combinations of all attributes (can be a CSV ﬁle) along with possible outcome for each combination for your intent. Provide at least 10 combinations. (Hint: You can use the same database which was created for Alexa chatbot)\n",
        "\n",
        "  * Create a CSV file for the allocated intent other than Zodiac sign.\n",
        "\n",
        "Upload the file and give the path in the below code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "EyzMvRbPAil_"
      },
      "outputs": [],
      "source": [
        "path_csv_zodiac = 'Chatbot/Zodiac_sign.csv'\n",
        "\n",
        "# YOUR CODE HERE for updating the path of csv file\n",
        "path_csv_store = '/content/Chatbot/Store_details.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjQr5bPZ3j40"
      },
      "source": [
        "### Task3 (5Marks)\n",
        "Text Representation and Classifications for both the intents\n",
        "\n",
        "To classify the intents based on user input, model must be trained on all the utterances given.\n",
        "- Iterate through the files from folder of utterances which ends with `.dat` extension\n",
        "- Create an array of train data and labels with respective class names (intent names)\n",
        "- Create a vector representation of train data (utterances) by using **any one** of the following process for the task:\n",
        "\n",
        "  - [Countvectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n",
        "\n",
        "    OR\n",
        "\n",
        "  - [TFIDFVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
        "\n",
        "- Perform a classification using the extracted features and classify the intent.\n",
        "    - ### **Expected Accuracy above 90%**\n",
        "\n",
        "- Predict the user_input using the trained model using intent_predict() method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiW8ZtRZExNV"
      },
      "source": [
        "**Data Loading:** Read all the utterances and extract the data (text) and labels for each intent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mq6rSmdnFzss",
        "outputId": "ece41c9c-eb65-475f-bc0a-ea70dd108257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['open my zodiac sign', 'get my zodiac sign', 'find out what my zodiac sign is', 'do you know what my zodiac sign is', 'zodiac sign', 'want to know my zodiac sign', 'what is my zodiac sign', 'can you give my zodiac sign', 'can you tell my zodiac sign', 'what about my zodiac sign', 'can you tell me what my zodiac sign is', 'what is your take on my zodiac sign', 'say my zodiac sign', 'tell my zodiac sign once more', 'please repeat my zodiac sign', 'please state my zodiac sign once more', 'i was born on $day $month $year what is my zodiac sign', 'tell zodiac sign for my birthday', 'for my birthday please tell me my zodiac sign', 'tell me my birthday zodiac sign', 'tell me my zodiac sign for my birthday', 'what is my zodiac sign', 'let me know my zodiac sign', 'what about my zodiac sign', 'please tell me what my zodiac sign is based on my birthday', 'could you please tell me what my zodiac sign is', 'whats the zodiac sign', 'what is my zodiac sign', 'i was born on $day $month $year', 'i was born on $month $day $year', 'i was born on $year $month $day', 'i was born on $day $month', 'i was born on $month $day', 'i was born on $month $year', 'in $month of $year i was born', 'i was born in $month', 'i was born on $year', 'i was born on $day', 'my birth day is on $day $month $year', 'my birthday is on $day $month $year', 'my birthday is $month $day $year', '$month', '$day', '$year', '$day $month', '$month $day', '$month $year', '$year $month', '$year $month $day', '$day $month $year']\n",
            "['get near by $category store details', 'get me near by $category store', 'get me near by $category store', 'get me near by $category store', 'get me $category shop near me', 'what is near by $category store', 'what is near by $category store', 'what is near by $category store', 'can you please tel me near by store for $category', 'can you tel me near by store for groceries', 'can you tel me near by store for food', 'can you tel me near by store for water', 'can you tel me near by store for dry cleaning', 'i want food store near by', 'i want dry cleaning store near by', 'i want $store', 'is $store $category now', 'what is $location of $store', 'please tel the $store $location', 'is the $store closed', 'where is $store $location', '$store $location $category', '$store $category', '$location of $store', '$category of $store', 'get me $category store', 'i want choclates', 'i want vegetables near by', 'i want icecream near by', 'i want milk near by', 'can you please give me medicines near by', 'can you please suggest near by good icecream shop', 'can you please suggest good grocery shop near by', 'i want water urgently where can i get', 'i want vegetables urgently where can i get', 'i want pencil shop', 'i want shop for pen and books near by', 'i want shop for toys near by', 'can you please suggest toys near by', 'can you please suggest medcines near by', 'I have headache, i want medicine', 'i have body pains , I want medicine', 'I am not well, can you please suggest some near by shop for medicines', 'I am not feeling well , I want water and medicine', 'where can i get good ice cream', 'i want pulses near by', 'i want cool drink shop near by', 'where will i get pepsi and coke', 'where will i get good shop for groceries', 'i want bread near by']\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE for loading and preparing the data\n",
        "from nltk import tokenize\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "utterances = []\n",
        "with open('Chatbot/utterances/get_Zodiac_Sign.dat', 'r') as myfile:\n",
        "    for line in myfile.readlines():\n",
        "        utterance = tokenize.sent_tokenize(line)\n",
        "        utterances = np.append(utterances, utterance)\n",
        "utteranceszodiac = list(utterances)\n",
        "print(utteranceszodiac)\n",
        "utterances = []\n",
        "with open('Chatbot/utterances/get_Store_details.dat', 'r') as myfile:\n",
        "    for line in myfile.readlines():\n",
        "        utterance = tokenize.sent_tokenize(line)\n",
        "        utterances = np.append(utterances, utterance)\n",
        "utterancesstore = list(utterances)\n",
        "print(utterancesstore)\n",
        "tag_map = defaultdict(lambda : wn.NOUN)\n",
        "tag_map['J'] = wn.ADJ\n",
        "tag_map['V'] = wn.VERB\n",
        "tag_map['R'] = wn.ADV\n",
        "#print(utterances)\n",
        "#len(utterances)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bT8oZHnF-TT"
      },
      "source": [
        "**Features extraction:** Fit the extracted text data with vectorizer to get the features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-Og4IX5ZYRm"
      },
      "source": [
        "**Classification:**\n",
        "\n",
        "* Identify the features and labels\n",
        "* Use train_test_split for splitting the train and test data\n",
        "* Fit your model on the train set using fit() and perform prediction on the test set using predict()\n",
        "* Get the accuracy of the model\n",
        "\n",
        "        Expected Accuracy above 90%\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjopuMddGHc9",
        "outputId": "5a746c60-f972-4905-a442-04c5ca8d010f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-3a866e044a1b>:76: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df=utteranceszodiacdf.append(utterancesstoredf)\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE to extract the features\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "utteranceszodiacdf=pd.DataFrame(utteranceszodiac)\n",
        "utteranceszodiacdf.rename(columns={0:'Features'}, inplace=True)\n",
        "\n",
        "utteranceszodiacdf['Features'].dropna(inplace=True)\n",
        "\n",
        "# 2. Changing all text to lowercase\n",
        "utteranceszodiacdf['Features'] = [entry.lower() for entry in utteranceszodiacdf['Features']]\n",
        "\n",
        "# 3. Tokenization-In this each entry in the corpus will be broken into set of words\n",
        "utteranceszodiacdf['Features']= [word_tokenize(entry) for entry in utteranceszodiacdf['Features']]\n",
        "\n",
        "utteranceszodiacdf.head()\n",
        "\n",
        "for index,entry in enumerate(utteranceszodiacdf['Features']):\n",
        "    # Declaring Empty List to store the words that follow the rules for this step\n",
        "    Final_words = []\n",
        "\n",
        "    # Initializing WordNetLemmatizer()\n",
        "    word_Lemmatized = WordNetLemmatizer()\n",
        "\n",
        "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
        "    for word, tag in pos_tag(entry):\n",
        "\n",
        "        # Below condition is to check for Stop words and consider only alphabets\n",
        "        if word not in stopwords.words('english') and word.isalpha():\n",
        "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
        "            Final_words.append(word)\n",
        "\n",
        "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
        "    utteranceszodiacdf.loc[index,'text_final'] = str(Final_words)\n",
        "    utteranceszodiacdf[\"Label\"]=\"get_Zodiac_Sign\"\n",
        "utteranceszodiacdf.head()\n",
        "utterancesstoredf=pd.DataFrame(utterancesstore)\n",
        "utterancesstoredf.rename(columns={0:'Features'}, inplace=True)\n",
        "\n",
        "utterancesstoredf['Features'].dropna(inplace=True)\n",
        "\n",
        "# 2. Changing all text to lowercase\n",
        "utterancesstoredf['Features'] = [entry.lower() for entry in utterancesstoredf['Features']]\n",
        "\n",
        "# 3. Tokenization-In this each entry in the corpus will be broken into set of words\n",
        "utterancesstoredf['Features']= [word_tokenize(entry) for entry in utterancesstoredf['Features']]\n",
        "\n",
        "utterancesstoredf.head()\n",
        "\n",
        "for index,entry in enumerate(utterancesstoredf['Features']):\n",
        "    # Declaring Empty List to store the words that follow the rules for this step\n",
        "    Final_words = []\n",
        "\n",
        "    # Initializing WordNetLemmatizer()\n",
        "    word_Lemmatized = WordNetLemmatizer()\n",
        "\n",
        "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
        "    for word, tag in pos_tag(entry):\n",
        "\n",
        "        # Below condition is to check for Stop words and consider only alphabets\n",
        "        if word not in stopwords.words('english') and word.isalpha():\n",
        "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
        "            Final_words.append(word)\n",
        "\n",
        "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
        "    utterancesstoredf.loc[index,'text_final'] = str(Final_words)\n",
        "    utterancesstoredf[\"Label\"]=\"get_Store_details\"\n",
        "utterancesstoredf.head()\n",
        "df=utteranceszodiacdf.append(utterancesstoredf)\n",
        "df.to_csv('final.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrGHpAqgMp07",
        "outputId": "39a2994b-838c-4ef1-b46f-1ee79fe847e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy Score ->  100.0\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE for classifying the intent\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text_final'], df['Label'], random_state = 0)\n",
        "Encoder = LabelEncoder()\n",
        "Train_Y = Encoder.fit_transform(y_train)\n",
        "Test_Y = Encoder.fit_transform(y_test)\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(X_train)\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "#Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
        "#Tfidf_vect.fit(df['text_final'])\n",
        "#Train_X_Tfidf = Tfidf_vect.transform(X_train)\n",
        "SVM=svm.SVC(kernel='linear',degree=3, probability=True)\n",
        "SVM.fit(X_train_tfidf,y_train)\n",
        "#Test_X_Tfidf = Tfidf_vect.transform(X_test)\n",
        "predictions_SVM = SVM.predict(count_vect.transform(X_test))\n",
        "#predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
        "#print(predictions_SVM)\n",
        "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, y_test)*100)\n",
        "\n",
        "\n",
        "#clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
        "#SVM=svm.SVC(kernel='poly',degree=3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMddI6OZTSdL"
      },
      "source": [
        "Predict the user_input using the trained model\n",
        "\n",
        "**Note:** intentPredict() function call is specified in the Conversation Flow\n",
        "- vectorize the given user_input\n",
        "- reshape the vectorized array using `reshape(1,-1)` as the user_input is only a single utterance\n",
        "- predict the label on the vectorized array\n",
        "- return the respective class (intent_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oaGk1MLg5E-k",
        "outputId": "893e677f-2baf-4ce9-9807-1751e48978fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'get_Zodiac_Sign'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# Take the user input as test data and predict using the model.\n",
        "\n",
        "def intentPredict(user_input):  # Do not change the function name\n",
        "  cnt1=count_vect.transform([user_input])\n",
        "       # YOUR CODE HERE for the prediction\n",
        " # print(SVM.predict(cnt1))\n",
        "  intent1=SVM.predict(cnt1)\n",
        "  #print(SVM.predict_proba(cnt1))\n",
        "  intent=str(intent1).strip(\"['']\")\n",
        "\n",
        "  return intent\n",
        "#intentPredict(\"get me grocery store\")\n",
        "intentPredict(\"get me zodiac sign\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EuAOMEtbB35"
      },
      "source": [
        "### Task4 (4Marks):\n",
        "\n",
        "Compare the attributes with the CSV file and get the final selection of that particular intent.\n",
        "\n",
        "  * Action function for the zodiac sign is already given. Similarly create action function for your intents and give the function name as mentioned in the params.cfg file.\n",
        "  * Use session object to take user inputs. (ex: `session.attributes`)\n",
        "\n",
        "Below are the 2 action functions to be performed:\n",
        "  1. Zodiac Sign Action\n",
        "  2. Your allocated Intent Action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySQgq901aaCH"
      },
      "source": [
        "1. Below Action function is given for\n",
        "Zodiac_Sign intent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RAucdXx3w0rt"
      },
      "outputs": [],
      "source": [
        "# Note: Zodiac_sign.csv records are taken from the internet; however it is open to adding multiple records.\n",
        "\n",
        "# Performs action for zodiac sign with csv file as source\n",
        "def zodiacSign_Action():\n",
        "    # global session\n",
        "    attr = session.attributes\n",
        "    year = int(attr['year'])\n",
        "    month = attr['month'] # month is a string, convert it to a month index\n",
        "    day = int(attr['day'])\n",
        "    df = pd.read_csv(path_csv_zodiac)\n",
        "    zodiac = \"\"\n",
        "\n",
        "    try:\n",
        "        month = int(datetime.datetime.strptime(month,'%b').strftime('%m'))\n",
        "    except:\n",
        "        month = int(datetime.datetime.strptime(month,'%B').strftime('%m'))\n",
        "\n",
        "    try:\n",
        "        usr_dob = (month,day)\n",
        "        datetime.datetime(year, month, day)\n",
        "        for index, row in df.iterrows():\n",
        "          if filter(row['Start']) <= usr_dob <= filter(row['End']):\n",
        "            zodiac = row['Zodiac']\n",
        "        return \"Your Zodiac sign is \" + zodiac\n",
        "    except ValueError:\n",
        "        return \"This is not a valid date\"\n",
        "\n",
        "def filter(X):\n",
        "    date = X.split()\n",
        "    month = int(datetime.datetime.strptime(date[0],'%B').strftime('%m'))\n",
        "    day = int(datetime.datetime.strptime(date[1],'%d').strftime('%d'))\n",
        "    return (month,day)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmGzfjZxYeVl"
      },
      "source": [
        "2. Define Action function for your allocated Intent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "g9rKIhzWNf2n"
      },
      "outputs": [],
      "source": [
        "# Note: Zodiac_sign.csv records are taken from the internet; however it is open to adding multiple records.\n",
        "\n",
        "# Performs action for zodiac sign with csv file as source\n",
        "def storedetails_Action():\n",
        "    # global session\n",
        "    attr = session.attributes\n",
        "    category = attr['category']\n",
        "    location = attr['location']\n",
        "    store = attr['store']\n",
        "    # month is a string, convert it to a month index\n",
        "    #availability = attr['availability']\n",
        "    df = pd.read_csv(path_csv_store)\n",
        "    foundstore=\"\"\n",
        "    #print(store,location,category)\n",
        "\n",
        "\n",
        "    try:\n",
        "        for index, row in df.iterrows():\n",
        "           availability = \"\"\n",
        "           #if (row['Store'] == store) and (row['Location'] == location) and (row['Category'] == category) :\n",
        "           if (row['Location'] == location) and (row['Category'] == category) and  (row['Store'] == store):\n",
        "              #Store = row['Store']\n",
        "              availability= row['Availability']\n",
        "              #storetiming=row['Store timings']\n",
        "           #if (Store != \"\" and availability!=\"\"and availability.lower()=='yes' ):\n",
        "            #   foundstore=\"yes\";\n",
        "             #  result=result+\",\"+Store+\"  available timings:\"+storetiming;\n",
        "              result=availability\n",
        "\n",
        "\n",
        "              return result;\n",
        "    except ValueError:\n",
        "        return \"This is not a valid store\";"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SH_FmK4w_nue"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJHrDux6Ho-K"
      },
      "source": [
        "### Task5 (3Marks)\n",
        "\n",
        "Run and test the Python chatbot for both the intents with the following:\n",
        "  - Python Chatbot should identify the user requirement.\n",
        "  - Gather the data from user input and get the relevant output.\n",
        "  - It should prompt the user with different prompts if the required input is not fulfilled.\n",
        "  - It should shift between the intents and maintain the dialogue flow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nzznhcEm-vO"
      },
      "source": [
        "Chatbot configuration class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "4S4rXiz9CQzo"
      },
      "outputs": [],
      "source": [
        "class BOT_config():\n",
        "    def __init__(self, session):\n",
        "        self.welcome='BOT: Hi! Welcome , How may i assist you?'\n",
        "        self.exits=[\"finish\",\"exit\",\"end\",\"quit\",\"stop\",\"close\", \"Bye\"]\n",
        "        if session.context.name == 'IntentComplete':\n",
        "            session.attributes = {}\n",
        "            session.context = FirstGreeting()\n",
        "            session.current_intent = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMHpVbnWnDo_"
      },
      "source": [
        "#### Conversational Chatbot\n",
        "\n",
        "Interact with bot by giving any utterance\n",
        "\n",
        "Ex:  `find zodiac sign`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycL4LskDEULN",
        "outputId": "3eb561c1-4034-4bbb-f14c-990f577efef8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BOT: Hi! Welcome , How may i assist you?\n",
            "User: i want bread\n",
            "BOT: ('which store are you looking for?', {})\n",
            "User: Vijetha\n",
            "BOT: ('location please', {'store': 'Vijetha'})\n",
            "User: Hydernagar\n",
            "BOT: ('Is it medical stationary dry cleaning grocery that you are looking for', {'store': 'Vijetha', 'location': 'Hydernagar'})\n",
            "User: grocery\n",
            "BOT: ('Yes', {'store': 'Vijetha', 'location': 'Hydernagar', 'category': 'Grocery'})\n",
            "User: zodiac \n",
            "BOT: ('I was born on 6th July when were you born', {})\n",
            "User: oct 11\n",
            "BOT: ('What is your year of birth?', {'day': '11', 'month': 'Oct'})\n",
            "User: 1990\n",
            "BOT: ('Your Zodiac sign is Libra', {'day': '11', 'month': 'Oct', 'year': '1990'})\n",
            "User: exit\n"
          ]
        }
      ],
      "source": [
        "session = Session()\n",
        "print(BOT_config(session).welcome)\n",
        "while (True):\n",
        "    inp = input('User: ')\n",
        "    if inp in BOT_config(session).exits:\n",
        "        break\n",
        "    prompt = session.reply(inp)\n",
        "    print ('BOT:', prompt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QzKd9K6Ra6q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RM2gkpedi0d2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}